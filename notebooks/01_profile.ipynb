{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9315d4",
   "metadata": {},
   "source": [
    "# IT Service Desk and Support Operations Analytics\n",
    "## Notebook 01: Data Profiling, KPI Foundations, and QA Checks\n",
    "\n",
    "This notebook profiles the IT Service Management (ITSM) dataset and prepares it for analytics and reporting.\n",
    "\n",
    "### Goals\n",
    "- Confirm dataset structure and allowed values\n",
    "- Parse time columns into usable datetime types\n",
    "- Create derived KPI-ready columns (durations and flags)\n",
    "- Run data quality checks (duplicates, chronology, SLA reconciliation)\n",
    "- Export an analytics-ready dataset for SQL loading and BI dashboards\n",
    "\n",
    "### Inputs and Outputs\n",
    "- Input: `../data/raw/itsm_raw.csv`\n",
    "- Output: `../data/processed/itsm_clean.csv`\n",
    "\n",
    "### Notes\n",
    "- This dataset is synthetic (educational). Results are still useful to demonstrate an end-to-end operational analytics pipeline.\n",
    "- SLA targets are modeled as deadline timestamps (not durations). We compute SLA compliance by comparing actual timestamps to SLA deadlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6601ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you see a ModuleNotFoundError, activate your virtual environment and install requirements.\n",
    "# In PowerShell (Windows):\n",
    "#   Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
    "#   .\\.venv\\Scripts\\Activate.ps1\n",
    "#   pip install -r requirements.txt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542c3c9",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "\n",
    "We load the raw CSV. The raw file is treated as read-only source data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3dedf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update this path only if your repo structure is different.\n",
    "RAW_PATH = \"../data/raw/itsm_raw.csv\"\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c2bd2",
   "metadata": {},
   "source": [
    "## 2. Basic inspection\n",
    "\n",
    "We inspect column names, data types, and a sample of records. This helps confirm the dataset matches expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b616616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Status',\n",
       " 'Ticket ID',\n",
       " 'Priority',\n",
       " 'Source',\n",
       " 'Topic',\n",
       " 'Agent Group',\n",
       " 'Agent Name',\n",
       " 'Created time',\n",
       " 'Expected SLA to resolve',\n",
       " 'Expected SLA to first response',\n",
       " 'First response time',\n",
       " 'SLA For first response',\n",
       " 'Resolution time',\n",
       " 'SLA For Resolution',\n",
       " 'Close time',\n",
       " 'Agent interactions',\n",
       " 'Survey results',\n",
       " 'Product group',\n",
       " 'Support Level',\n",
       " 'Country',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names\n",
    "list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e8fbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status                                str\n",
       "Ticket ID                             str\n",
       "Priority                              str\n",
       "Source                                str\n",
       "Topic                                 str\n",
       "Agent Group                           str\n",
       "Agent Name                            str\n",
       "Created time                          str\n",
       "Expected SLA to resolve               str\n",
       "Expected SLA to first response        str\n",
       "First response time                   str\n",
       "SLA For first response                str\n",
       "Resolution time                       str\n",
       "SLA For Resolution                    str\n",
       "Close time                            str\n",
       "Agent interactions                  int64\n",
       "Survey results                        str\n",
       "Product group                         str\n",
       "Support Level                         str\n",
       "Country                               str\n",
       "Latitude                          float64\n",
       "Longitude                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7c06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Agent Group</th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Created time</th>\n",
       "      <th>Expected SLA to resolve</th>\n",
       "      <th>Expected SLA to first response</th>\n",
       "      <th>...</th>\n",
       "      <th>Resolution time</th>\n",
       "      <th>SLA For Resolution</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Agent interactions</th>\n",
       "      <th>Survey results</th>\n",
       "      <th>Product group</th>\n",
       "      <th>Support Level</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Closed</td>\n",
       "      <td>TCKT-100000</td>\n",
       "      <td>High</td>\n",
       "      <td>Email</td>\n",
       "      <td>General Inquiry</td>\n",
       "      <td>Security</td>\n",
       "      <td>Khalid Al-Salem</td>\n",
       "      <td>2024-07-04 12:42:00</td>\n",
       "      <td>2024-07-04 14:42:00</td>\n",
       "      <td>2024-07-04 13:12:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-07-04 14:30:00</td>\n",
       "      <td>Met</td>\n",
       "      <td>2024-07-04 14:32:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>L3</td>\n",
       "      <td>Oman</td>\n",
       "      <td>25.1856</td>\n",
       "      <td>50.9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Closed</td>\n",
       "      <td>TCKT-100001</td>\n",
       "      <td>High</td>\n",
       "      <td>Chat</td>\n",
       "      <td>Network Issue</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Ahmed Al-Sabah</td>\n",
       "      <td>2024-05-23 20:03:00</td>\n",
       "      <td>2024-05-23 22:03:00</td>\n",
       "      <td>2024-05-23 20:33:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-05-23 22:00:00</td>\n",
       "      <td>Met</td>\n",
       "      <td>2024-05-23 22:05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Dissatisfied</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>L2</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>23.2741</td>\n",
       "      <td>55.3867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Progress</td>\n",
       "      <td>TCKT-100002</td>\n",
       "      <td>Low</td>\n",
       "      <td>Phone</td>\n",
       "      <td>General Inquiry</td>\n",
       "      <td>Development</td>\n",
       "      <td>Mohammed Al-Mansoori</td>\n",
       "      <td>2024-04-13 20:51:00</td>\n",
       "      <td>2024-04-14 00:51:00</td>\n",
       "      <td>2024-04-13 21:51:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-04-14 00:47:00</td>\n",
       "      <td>Met</td>\n",
       "      <td>2024-04-14 00:51:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Dissatisfied</td>\n",
       "      <td>Software</td>\n",
       "      <td>L1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>23.6264</td>\n",
       "      <td>50.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resolved</td>\n",
       "      <td>TCKT-100003</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>Access Request</td>\n",
       "      <td>Development</td>\n",
       "      <td>Mohammed Al-Khalifa</td>\n",
       "      <td>2024-05-13 12:50:00</td>\n",
       "      <td>2024-05-13 13:50:00</td>\n",
       "      <td>2024-05-13 13:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-05-13 13:48:00</td>\n",
       "      <td>Met</td>\n",
       "      <td>2024-05-13 13:53:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Dissatisfied</td>\n",
       "      <td>Network</td>\n",
       "      <td>L2</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>25.0736</td>\n",
       "      <td>54.8437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Closed</td>\n",
       "      <td>TCKT-100004</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Portal</td>\n",
       "      <td>Hardware Failure</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Hassan Al-Nasser</td>\n",
       "      <td>2024-06-19 22:51:00</td>\n",
       "      <td>2024-06-19 23:51:00</td>\n",
       "      <td>2024-06-19 23:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-06-19 23:49:00</td>\n",
       "      <td>Met</td>\n",
       "      <td>2024-06-19 23:54:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>L3</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>24.7362</td>\n",
       "      <td>51.4839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Status    Ticket ID  Priority  Source             Topic  \\\n",
       "0       Closed  TCKT-100000      High   Email   General Inquiry   \n",
       "1       Closed  TCKT-100001      High    Chat     Network Issue   \n",
       "2  In Progress  TCKT-100002       Low   Phone   General Inquiry   \n",
       "3     Resolved  TCKT-100003  Critical    Chat    Access Request   \n",
       "4       Closed  TCKT-100004  Critical  Portal  Hardware Failure   \n",
       "\n",
       "        Agent Group            Agent Name         Created time  \\\n",
       "0          Security       Khalid Al-Salem  2024-07-04 12:42:00   \n",
       "1  Customer Service        Ahmed Al-Sabah  2024-05-23 20:03:00   \n",
       "2       Development  Mohammed Al-Mansoori  2024-04-13 20:51:00   \n",
       "3       Development   Mohammed Al-Khalifa  2024-05-13 12:50:00   \n",
       "4  Customer Service      Hassan Al-Nasser  2024-06-19 22:51:00   \n",
       "\n",
       "  Expected SLA to resolve Expected SLA to first response  ...  \\\n",
       "0     2024-07-04 14:42:00            2024-07-04 13:12:00  ...   \n",
       "1     2024-05-23 22:03:00            2024-05-23 20:33:00  ...   \n",
       "2     2024-04-14 00:51:00            2024-04-13 21:51:00  ...   \n",
       "3     2024-05-13 13:50:00            2024-05-13 13:00:00  ...   \n",
       "4     2024-06-19 23:51:00            2024-06-19 23:01:00  ...   \n",
       "\n",
       "       Resolution time SLA For Resolution           Close time  \\\n",
       "0  2024-07-04 14:30:00                Met  2024-07-04 14:32:00   \n",
       "1  2024-05-23 22:00:00                Met  2024-05-23 22:05:00   \n",
       "2  2024-04-14 00:47:00                Met  2024-04-14 00:51:00   \n",
       "3  2024-05-13 13:48:00                Met  2024-05-13 13:53:00   \n",
       "4  2024-06-19 23:49:00                Met  2024-06-19 23:54:00   \n",
       "\n",
       "  Agent interactions Survey results  Product group Support Level  Country  \\\n",
       "0                  5        Neutral          Cloud            L3     Oman   \n",
       "1                  4   Dissatisfied          Cloud            L2    Qatar   \n",
       "2                  3   Dissatisfied       Software            L1  Bahrain   \n",
       "3                  5   Dissatisfied        Network            L2   Kuwait   \n",
       "4                  4        Neutral       Hardware            L3    Qatar   \n",
       "\n",
       "  Latitude Longitude  \n",
       "0  25.1856   50.9447  \n",
       "1  23.2741   55.3867  \n",
       "2  23.6264   50.1302  \n",
       "3  25.0736   54.8437  \n",
       "4  24.7362   51.4839  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a few rows (subset of columns for readability)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b59c2",
   "metadata": {},
   "source": [
    "## 3. Missing values and uniqueness checks\n",
    "\n",
    "Even if the dataset is clean, we verify:\n",
    "- No unexpected nulls\n",
    "- Ticket ID can be used as a primary key (no duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ccf33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status                            0\n",
       "Ticket ID                         0\n",
       "Priority                          0\n",
       "Source                            0\n",
       "Topic                             0\n",
       "Agent Group                       0\n",
       "Agent Name                        0\n",
       "Created time                      0\n",
       "Expected SLA to resolve           0\n",
       "Expected SLA to first response    0\n",
       "First response time               0\n",
       "SLA For first response            0\n",
       "Resolution time                   0\n",
       "SLA For Resolution                0\n",
       "Close time                        0\n",
       "Agent interactions                0\n",
       "Survey results                    0\n",
       "Product group                     0\n",
       "Support Level                     0\n",
       "Country                           0\n",
       "Latitude                          0\n",
       "Longitude                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values per column\n",
    "df.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d6b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Ticket IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Duplicate check on the primary key candidate\n",
    "dup_ticket_ids = df.duplicated(subset=[\"Ticket ID\"]).sum()\n",
    "print(\"Duplicate Ticket IDs:\", dup_ticket_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543a7c2",
   "metadata": {},
   "source": [
    "## 4. Allowed values and distributions\n",
    "\n",
    "These checks confirm the observed allowed values for categorical fields.\n",
    "They also help set expectations for dashboard filters and KPI groupings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25522c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "Resolved       20134\n",
       "In Progress    20123\n",
       "Closed         20015\n",
       "New            20014\n",
       "Open           19714\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Status distribution\n",
    "df[\"Status\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70d92ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Priority\n",
       "Medium      25117\n",
       "Critical    25045\n",
       "Low         25014\n",
       "High        24824\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Priority distribution\n",
    "df[\"Priority\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813d5379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent Group\n",
       "Development         20158\n",
       "Network Ops         20144\n",
       "Security            19985\n",
       "Customer Service    19884\n",
       "IT Support          19829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Group distribution (top 10)\n",
    "df[\"Agent Group\"].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df100704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey results\n",
       "Dissatisfied    33409\n",
       "Neutral         33345\n",
       "Satisfied       33246\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survey results distribution\n",
    "df[\"Survey results\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc1602",
   "metadata": {},
   "source": [
    "## 5. Parse time columns into datetime\n",
    "\n",
    "Time columns arrive as strings in the raw CSV. We convert them to datetime so we can:\n",
    "- Calculate durations (first response time, resolution time)\n",
    "- Compare actual timestamps against SLA deadline timestamps\n",
    "- Validate chronological ordering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856c1417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Created time                      0\n",
       "First response time               0\n",
       "Resolution time                   0\n",
       "Close time                        0\n",
       "Expected SLA to first response    0\n",
       "Expected SLA to resolve           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_cols = [\n",
    "    \"Created time\",\n",
    "    \"First response time\",\n",
    "    \"Resolution time\",\n",
    "    \"Close time\",\n",
    "    \"Expected SLA to first response\",\n",
    "    \"Expected SLA to resolve\",\n",
    "]\n",
    "\n",
    "# Convert to datetime; errors='raise' will surface formatting issues early\n",
    "for c in time_cols:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"raise\")\n",
    "\n",
    "# Confirm parsing produced no missing timestamps\n",
    "df[time_cols].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425423e",
   "metadata": {},
   "source": [
    "## 6. Create KPI-ready derived columns\n",
    "\n",
    "Create reusable columns that will be used consistently across:\n",
    "- Python analysis\n",
    "- SQL queries\n",
    "- Power BI or Excel dashboard measures\n",
    "\n",
    "Derived columns:\n",
    "- `first_response_minutes`\n",
    "- `resolution_minutes`\n",
    "- `response_sla_met_recalc`\n",
    "- `resolution_sla_met_recalc`\n",
    "- `backlog_flag`\n",
    "- `satisfaction_score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e0dd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_response_minutes</th>\n",
       "      <th>resolution_minutes</th>\n",
       "      <th>backlog_flag</th>\n",
       "      <th>satisfaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_response_minutes  resolution_minutes  backlog_flag  \\\n",
       "0                    20.0               108.0         False   \n",
       "1                    22.0               117.0         False   \n",
       "2                    50.0               236.0          True   \n",
       "3                     0.0                58.0         False   \n",
       "4                     9.0                58.0         False   \n",
       "\n",
       "   satisfaction_score  \n",
       "0                   2  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duration metrics in minutes\n",
    "df[\"first_response_minutes\"] = (df[\"First response time\"] - df[\"Created time\"]).dt.total_seconds() / 60\n",
    "df[\"resolution_minutes\"] = (df[\"Resolution time\"] - df[\"Created time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# SLA compliance (recalculated from timestamps and SLA deadlines)\n",
    "df[\"response_sla_met_recalc\"] = df[\"First response time\"] <= df[\"Expected SLA to first response\"]\n",
    "df[\"resolution_sla_met_recalc\"] = df[\"Resolution time\"] <= df[\"Expected SLA to resolve\"]\n",
    "\n",
    "# Backlog definition (open work)\n",
    "backlog_statuses = [\"New\", \"Open\", \"In Progress\"]\n",
    "df[\"backlog_flag\"] = df[\"Status\"].isin(backlog_statuses)\n",
    "\n",
    "# Satisfaction score for numeric analysis\n",
    "satisfaction_map = {\"Satisfied\": 3, \"Neutral\": 2, \"Dissatisfied\": 1}\n",
    "df[\"satisfaction_score\"] = df[\"Survey results\"].map(satisfaction_map)\n",
    "\n",
    "df[[\"first_response_minutes\", \"resolution_minutes\", \"backlog_flag\", \"satisfaction_score\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc669664",
   "metadata": {},
   "source": [
    "## 7. QA checks\n",
    "\n",
    "These checks make the pipeline trustworthy.\n",
    "\n",
    "### 7.1 Duration integrity\n",
    "Durations should never be negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80cc3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative first_response_minutes: 0\n",
      "Negative resolution_minutes: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_response_minutes</th>\n",
       "      <th>resolution_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.256900</td>\n",
       "      <td>140.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.765417</td>\n",
       "      <td>67.378202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_response_minutes  resolution_minutes\n",
       "count           100000.000000       100000.000000\n",
       "mean                31.256900          140.073900\n",
       "std                 18.765417           67.378202\n",
       "min                  0.000000           40.000000\n",
       "25%                 10.000000           60.000000\n",
       "50%                 35.000000          160.000000\n",
       "75%                 50.000000          220.000000\n",
       "max                 60.000000          240.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Negative first_response_minutes:\", (df[\"first_response_minutes\"] < 0).sum())\n",
    "print(\"Negative resolution_minutes:\", (df[\"resolution_minutes\"] < 0).sum())\n",
    "\n",
    "df[[\"first_response_minutes\", \"resolution_minutes\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0273ff4",
   "metadata": {},
   "source": [
    "### 7.2 Chronological integrity\n",
    "\n",
    "Expected ordering:\n",
    "- Created time <= First response time <= Resolution time <= Close time\n",
    "\n",
    "Any violations indicate inconsistent timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22a07ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response before Created time: 0\n",
      "Resolution before First response: 0\n",
      "Close time before Resolution time: 0\n"
     ]
    }
   ],
   "source": [
    "bad_created_to_response = (df[\"First response time\"] < df[\"Created time\"]).sum()\n",
    "bad_response_to_resolution = (df[\"Resolution time\"] < df[\"First response time\"]).sum()\n",
    "bad_resolution_to_close = (df[\"Close time\"] < df[\"Resolution time\"]).sum()\n",
    "\n",
    "print(\"First response before Created time:\", bad_created_to_response)\n",
    "print(\"Resolution before First response:\", bad_response_to_resolution)\n",
    "print(\"Close time before Resolution time:\", bad_resolution_to_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6ab52",
   "metadata": {},
   "source": [
    "### 7.3 SLA reconciliation\n",
    "\n",
    "The dataset contains provided SLA labels:\n",
    "- `SLA For first response`\n",
    "- `SLA For Resolution`\n",
    "\n",
    "Validate them by converting labels to boolean flags and comparing against our recalculated SLA results.\n",
    "This is a common enterprise QA practice to confirm KPI logic matches the source system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9aae786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response SLA flag matches recalculation:\n",
      "True    100000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resolution SLA flag matches recalculation:\n",
      "True    100000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert provided SLA labels into boolean flags\n",
    "df[\"response_sla_flag_bool\"] = df[\"SLA For first response\"].astype(str).str.strip().eq(\"Met\")\n",
    "df[\"resolution_sla_flag_bool\"] = df[\"SLA For Resolution\"].astype(str).str.strip().eq(\"Met\")\n",
    "\n",
    "print(\"Response SLA flag matches recalculation:\")\n",
    "print((df[\"response_sla_met_recalc\"] == df[\"response_sla_flag_bool\"]).value_counts())\n",
    "\n",
    "print(\"\\nResolution SLA flag matches recalculation:\")\n",
    "print((df[\"resolution_sla_met_recalc\"] == df[\"resolution_sla_flag_bool\"]).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15df591",
   "metadata": {},
   "source": [
    "## 8. Quick KPI snapshots (sanity checks)\n",
    "\n",
    "These are lightweight checks to confirm the derived columns behave as expected.\n",
    "They are not final dashboard visuals yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8c9244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tickets_total': 100000,\n",
       " 'first_response_median_min': 35.0,\n",
       " 'resolution_median_min': 160.0,\n",
       " 'backlog_open_tickets': 59851,\n",
       " 'satisfaction_avg_score': 1.99837}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Median times are generally more robust than means when outliers exist\n",
    "kpi_snapshot = {\n",
    "    \"tickets_total\": len(df),\n",
    "    \"first_response_median_min\": float(df[\"first_response_minutes\"].median()),\n",
    "    \"resolution_median_min\": float(df[\"resolution_minutes\"].median()),\n",
    "    \"backlog_open_tickets\": int(df[\"backlog_flag\"].sum()),\n",
    "    \"satisfaction_avg_score\": float(df[\"satisfaction_score\"].mean()),\n",
    "}\n",
    "kpi_snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06977908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response SLA compliance rate: 1.0\n",
      "Resolution SLA compliance rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SLA compliance rates (recalculated)\n",
    "response_sla_rate = df[\"response_sla_met_recalc\"].mean()\n",
    "resolution_sla_rate = df[\"resolution_sla_met_recalc\"].mean()\n",
    "\n",
    "print(\"Response SLA compliance rate:\", response_sla_rate)\n",
    "print(\"Resolution SLA compliance rate:\", resolution_sla_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68a73f",
   "metadata": {},
   "source": [
    "## 9. Export analytics-ready dataset\n",
    "\n",
    "Export a processed dataset that includes derived columns and validated timestamps.\n",
    "This file is used for:\n",
    "- Loading into PostgreSQL (fact table)\n",
    "- Power BI or Excel dashboards\n",
    "- Reproducible pipeline execution\n",
    "\n",
    "Raw data remains unchanged in `data/raw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7868952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/processed/itsm_clean.csv\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_PATH = \"../data/processed/itsm_clean.csv\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "from pathlib import Path\n",
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.to_csv(PROCESSED_PATH, index=False)\n",
    "print(\"Saved:\", PROCESSED_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
